# -*- coding: utf-8 -*-
"""Toxic_Comment_Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1j5MA_VVnI52wbNCQUTk4jzp0Xk4lCDri

CSL2050: PRML

**MAJOR PROJECT**


**Toxic Comment Classification Using Machine Learning**


by


**Narkhede Kartik Sanjay (B21EE041)**


**Raunak Garg (B21EE056)**


**Samarth Sudhirkumar Bhalerao (B21EE060)**

#Importing libraries
"""

#import required packages
#basics
import pandas as pd
import numpy as np

#misc
import gc
import time
import warnings

#stats
#from scipy.misc import imread
from scipy import sparse
import scipy.stats as ss

#viz
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
import seaborn as sns
from wordcloud import WordCloud ,STOPWORDS
from PIL import Image
import matplotlib_venn as venn

#nlp
import string
import re    #for regex
import nltk
from nltk.corpus import stopwords
import spacy
from nltk import pos_tag
from nltk.stem.wordnet import WordNetLemmatizer
from nltk.tokenize import word_tokenize
# Tweet tokenizer does not split at apostophes which is what we want
from nltk.tokenize import TweetTokenizer


#FeatureEngineering
from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, HashingVectorizer
from sklearn.decomposition import TruncatedSVD
from sklearn.base import BaseEstimator, ClassifierMixin
from sklearn.utils.validation import check_X_y, check_is_fitted
from sklearn.linear_model import LogisticRegression
from sklearn import metrics
from sklearn.metrics import log_loss
from sklearn.model_selection import StratifiedKFold
from sklearn.model_selection import train_test_split

import warnings
warnings.simplefilter('ignore', category=DeprecationWarning)



from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, VotingClassifier
from sklearn.metrics import accuracy_score
import pickle
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import classification_report
from sklearn.utils.class_weight import compute_class_weight


!pip install emoji
!pip install contractions

"""#Importing datasets"""

from google.colab import drive
drive.mount('/content/gdrive')
df=pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/major_project/train.csv',header=None)
df.columns=["id","comment_text" , "toxic" , "severe_toxic" ,"obscene","threat","insult","identity_hate"]
df.drop(['id'], axis = 1, inplace = True)
df

"""#Undersampling method 1"""

# import pandas as pd
# from sklearn.cluster import KMeans

# # read in your original dataframe
# #df = pd.read_csv('your_data.csv')

# # specify the number of clusters
# num_clusters = 10

# # define the column names to exclude from the clustering process
# text_cols = ['comment_text', 'tokens','stop_removed','final_string'] # replace with the names of your text columns

# # create a subset of the dataframe with the text columns excluded
# df_numeric = df.drop(columns=text_cols)

# # create a KMeans object with the specified number of clusters
# kmeans = KMeans(n_clusters=num_clusters, random_state=42)

# # fit the KMeans model to the data
# kmeans.fit(df_numeric)

# # get the cluster labels for each row
# cluster_labels = kmeans.predict(df_numeric)

# # create an empty dataframe to store the undersampled data
# undersampled_df = pd.DataFrame()

# # for each cluster, select a representative subset of rows
# for i in range(num_clusters):
#     # get the indices of the rows belonging to the current cluster
#     indices = [j for j, label in enumerate(cluster_labels) if label == i]
#     # randomly select 10% of the rows from the current cluster
#     undersampled_indices = pd.Series(indices).sample(frac=0.1, random_state=42).tolist()
#     # add the selected rows to the undersampled dataframe
#     undersampled_df = pd.concat([undersampled_df, df.loc[undersampled_indices]])

# # reset the index of the undersampled dataframe
# undersampled_df_final = undersampled_df.reset_index(drop=True)
# undersampled_df_final

# # print the number of rows in the undersampled dataframe
# #print(f"Number of rows in undersampled dataframe: {undersampled_df.shape[0]}")

# col_sum = undersampled_df_final.iloc[:,1:].sum()
# row_sum = undersampled_df_final.iloc[:,1:].sum(axis = 1)

# undersampled_df_final['non_toxic'] = (row_sum == 0)

# print("Total comments = ", len(undersampled_df_final))
# print("Total non_toxic comments = ", undersampled_df_final['non_toxic'].sum())
# print("Count of each type of comment:")
# print(col_sum)

# balanced_df.to_csv('balanced_data.csv', index=False)
# balanced_df

# df = undersampled_df_final

"""This is basically giving us a smaller version of original dataset and thus we are discarding this smaller unbalanced data.

#Preprocessing and visualization
"""

na_val=df.isnull().sum()
print(na_val)

col_sum = df.iloc[:,1:].sum()
row_sum = df.iloc[:,1:].sum(axis = 1)

df['non_toxic'] = (row_sum == 0)

print("Total comments = ", len(df))
print("Total non_toxic comments = ", df['non_toxic'].sum())
print("Count of each type of comment:")
print(col_sum)

multi_val = row_sum.value_counts()

multi_val.values

def make_confusion_matrix(col1, col2):
    conf_mat = pd.crosstab(df[col1], df[col2])
    print("Confusion matrix:")
    print(conf_mat)

arr_col = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']
for i in arr_col:
    for j in arr_col:
        if(i != j):
            make_confusion_matrix(i, j)

df_toxic = df[df['toxic']==1]
print("Toxic comment:")
print(df_toxic.iloc[2,0])

df_severe_toxic = df[df['severe_toxic']==1]
print("Severe toxic comment:")
print(df_severe_toxic.iloc[0,0])

df_obscene = df[df['obscene']==1]
print("Obscene comment:")
print(df_obscene.iloc[3,0])

df_threat = df[df['threat']==1]
print("Threat comment:")
print(df_threat.iloc[2,0])

df_insult = df[df['insult']==1]
print("Insult comment:")
print(df_insult.iloc[6,0])

df_identity_hate = df[df['identity_hate']==1]
print("Identity Hate comment:")
print(df_identity_hate.iloc[10,0])

df

df_non_toxic = df[df['non_toxic']==1]

stopword=set(STOPWORDS)
non_toxic_comments = df_non_toxic['comment_text'].values
wc= WordCloud(max_words=1000,stopwords=stopword)
wc.generate(" ".join(non_toxic_comments))
plt.figure(figsize=(10,5))
plt.axis("off")
plt.title("Frequent words in Non-toxic Comments")
plt.imshow(wc.recolor(), alpha=0.95)
plt.show()

toxic_comments = df_toxic['comment_text'].values
wc= WordCloud(max_words=1000,stopwords=stopword)
wc.generate(" ".join(toxic_comments))
plt.figure(figsize=(10,5))
plt.axis("off")
plt.title("Frequent words in Toxic Comments")
plt.imshow(wc.recolor(), alpha=0.95)
plt.show()

severe_toxic_comments = df_severe_toxic['comment_text'].values
wc= WordCloud(max_words=1000,stopwords=stopword)
wc.generate(" ".join(severe_toxic_comments))
plt.figure(figsize=(10,5))
plt.axis("off")
plt.title("Frequent words in Severe-toxic Comments")
plt.imshow(wc.recolor(), alpha=0.95)
plt.show()

obscene_comments = df_obscene['comment_text'].values
wc= WordCloud(max_words=1000,stopwords=stopword)
wc.generate(" ".join(obscene_comments))
plt.figure(figsize=(10,5))
plt.axis("off")
plt.title("Frequent words in Obscene Comments")
plt.imshow(wc.recolor(), alpha=0.95)
plt.show()

threat_comments = df_threat['comment_text'].values
wc= WordCloud(max_words=1000,stopwords=stopword)
wc.generate(" ".join(threat_comments))
plt.figure(figsize=(10,5))
plt.axis("off")
plt.title("Frequent words in Threat Comments")
plt.imshow(wc.recolor(), alpha=0.95)
plt.show()

insult_comments = df_insult['comment_text'].values
wc= WordCloud(max_words=1000,stopwords=stopword)
wc.generate(" ".join(insult_comments))
plt.figure(figsize=(10,5))
plt.axis("off")
plt.title("Frequent words in Insult Comments")
plt.imshow(wc.recolor(), alpha=0.95)
plt.show()

identity_hate_comments =df_identity_hate['comment_text'].values
wc= WordCloud(max_words=1000,stopwords=stopword)
wc.generate(" ".join(identity_hate_comments))
plt.figure(figsize=(10,5))
plt.axis("off")
plt.title("Frequent words in Identity Hate Comments")
plt.imshow(wc.recolor(), alpha=0.95)
plt.show()

"""Data Cleaning"""

import emoji
import contractions
from textblob import TextBlob

def clean_text(text):

    text = str(text)
    text = text.lower()
    text = emoji.demojize(text)
    text = re.sub(r"https?://\S+|www\.\S+", "", text)
    html = re.compile(r"<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});")
    text = re.sub(html, "", text)
    text = re.sub(r'[^\x00-\x7f]',r'', text)
    text = text.translate(str.maketrans('', '', string.punctuation))
    text = re.sub(r"what's", "what is ", text)
    text = re.sub(r'[0-9]+', '', text)
    text = re.sub(r"\'s", " ", text)
    text = re.sub(r"\'ve", " have ", text)
    text = re.sub(r"can't", "cannot ", text)
    text = re.sub(r"n't", " not ", text)
    text = re.sub(r"i'm", "i am ", text)
    text = re.sub(r"\'re", " are ", text)
    text = re.sub(r"\'d", " would ", text)
    text = re.sub(r"\'ll", " will ", text)
    text = re.sub(r"\'scuse", " excuse ", text)
    text = re.sub('\W', ' ', text)
    text = re.sub('\s+', ' ', text)
    text = text.strip(' ')


    # manually removing

    sample_typos_slang = {
                                "w/e": "whatever",
                                "usagov": "usa government",
                                "recentlu": "recently",
                                "ph0tos": "photos",
                                "amirite": "am i right",
                                "exp0sed": "exposed",
                                "<3": "love",
                                "luv": "love",
                                "amageddon": "armageddon",
                                "trfc": "traffic",
                                "16yr": "16 year"
                                }

        # Acronyms
    sample_acronyms =  {
                        "mh370": "malaysia airlines flight 370",
                        "okwx": "oklahoma city weather",
                        "arwx": "arkansas weather",
                        "gawx": "georgia weather",
                        "scwx": "south carolina weather",
                        "cawx": "california weather",
                        "tnwx": "tennessee weather",
                        "azwx": "arizona weather",
                        "alwx": "alabama weather",
                        "usnwsgov": "united states national weather service",
                        "2mw": "tomorrow"
                        }


    # Some common abbreviations
    sample_abbr = {
                    "$" : " dollar ",
                    "€" : " euro ",
                    "4ao" : "for adults only",
                    "a.m" : "before midday",
                    "a3" : "anytime anywhere anyplace",
                    "aamof" : "as a matter of fact",
                    "acct" : "account",
                    "adih" : "another day in hell",
                    "afaic" : "as far as i am concerned",
                    "afaict" : "as far as i can tell",
                    "afaik" : "as far as i know",
                    "afair" : "as far as i remember",
                    "afk" : "away from keyboard",
                    "app" : "application",
                    "approx" : "approximately",
                    "apps" : "applications",
                    "asap" : "as soon as possible",
                    "asl" : "age, sex, location",
                    "atk" : "at the keyboard",
                    "ave." : "avenue",
                    "aymm" : "are you my mother",
                    "ayor" : "at your own risk",
                    "b&b" : "bed and breakfast",
                    "b+b" : "bed and breakfast",
                    "b.c" : "before christ",
                    "b2b" : "business to business",
                    "b2c" : "business to customer",
                    "b4" : "before",
                    "b4n" : "bye for now",
                    "b@u" : "back at you",
                    "bae" : "before anyone else",
                    "bak" : "back at keyboard",
                    "bbbg" : "bye bye be good",
                    "bbc" : "british broadcasting corporation",
                    "bbias" : "be back in a second",
                    "bbl" : "be back later",
                    "bbs" : "be back soon",
                    "be4" : "before",
                    "bfn" : "bye for now",
                    "blvd" : "boulevard",
                    "bout" : "about",
                    "brb" : "be right back",
                    "bros" : "brothers",
                    "brt" : "be right there",
                    "bsaaw" : "big smile and a wink",
                    "btw" : "by the way",
                    "bwl" : "bursting with laughter",
                    "c/o" : "care of",
                    "cet" : "central european time",
                    "cf" : "compare",
                    "cia" : "central intelligence agency",
                    "csl" : "can not stop laughing",
                    "cu" : "see you",
                    "cul8r" : "see you later",
                    "cv" : "curriculum vitae",
                    "cwot" : "complete waste of time",
                    "cya" : "see you",
                    "cyt" : "see you tomorrow",
                    "dae" : "does anyone else",
                    "dbmib" : "do not bother me i am busy",
                    "diy" : "do it yourself",
                    "dm" : "direct message",
                    "dwh" : "during work hours",
                    "e123" : "easy as one two three",
                    "eet" : "eastern european time",
                    "eg" : "example",
                    "embm" : "early morning business meeting",
                    "encl" : "enclosed",
                    "encl." : "enclosed",
                    "etc" : "and so on",
                    "faq" : "frequently asked questions",
                    "fawc" : "for anyone who cares",
                    "fb" : "facebook",
                    "fc" : "fingers crossed",
                    "fig" : "figure",
                    "fimh" : "forever in my heart",
                    "ft." : "feet",
                    "ft" : "featuring",
                    "ftl" : "for the loss",
                    "ftw" : "for the win",
                    "fwiw" : "for what it is worth",
                    "fyi" : "for your information",
                    "g9" : "genius",
                    "gahoy" : "get a hold of yourself",
                    "gal" : "get a life",
                    "gcse" : "general certificate of secondary education",
                    "gfn" : "gone for now",
                    "gg" : "good game",
                    "gl" : "good luck",
                    "glhf" : "good luck have fun",
                    "gmt" : "greenwich mean time",
                    "gmta" : "great minds think alike",
                    "gn" : "good night",
                    "g.o.a.t" : "greatest of all time",
                    "goat" : "greatest of all time",
                    "goi" : "get over it",
                    "gps" : "global positioning system",
                    "gr8" : "great",
                    "gratz" : "congratulations",
                    "gyal" : "girl",
                    "h&c" : "hot and cold",
                    "hp" : "horsepower",
                    "hr" : "hour",
                    "hrh" : "his royal highness",
                    "ht" : "height",
                    "ibrb" : "i will be right back",
                    "ic" : "i see",
                    "icq" : "i seek you",
                    "icymi" : "in case you missed it",
                    "idc" : "i do not care",
                    "idgadf" : "i do not give a damn fuck",
                    "idgaf" : "i do not give a fuck",
                    "idk" : "i do not know",
                    "ie" : "that is",
                    "i.e" : "that is",
                    "ifyp" : "i feel your pain",
                    "IG" : "instagram",
                    "iirc" : "if i remember correctly",
                    "ilu" : "i love you",
                    "ily" : "i love you",
                    "imho" : "in my humble opinion",
                    "imo" : "in my opinion",
                    "imu" : "i miss you",
                    "iow" : "in other words",
                    "irl" : "in real life",
                    "j4f" : "just for fun",
                    "jic" : "just in case",
                    "jk" : "just kidding",
                    "jsyk" : "just so you know",
                    "l8r" : "later",
                    "lb" : "pound",
                    "lbs" : "pounds",
                    "ldr" : "long distance relationship",
                    "lmao" : "laugh my ass off",
                    "lmfao" : "laugh my fucking ass off",
                    "lol" : "laughing out loud",
                    "ltd" : "limited",
                    "ltns" : "long time no see",
                    "m8" : "mate",
                    "mf" : "motherfucker",
                    "mfs" : "motherfuckers",
                    "mfw" : "my face when",
                    "mofo" : "motherfucker",
                    "mph" : "miles per hour",
                    "mr" : "mister",
                    "mrw" : "my reaction when",
                    "ms" : "miss",
                    "mte" : "my thoughts exactly",
                    "nagi" : "not a good idea",
                    "nbc" : "national broadcasting company",
                    "nbd" : "not big deal",
                    "nfs" : "not for sale",
                    "ngl" : "not going to lie",
                    "nhs" : "national health service",
                    "nrn" : "no reply necessary",
                    "nsfl" : "not safe for life",
                    "nsfw" : "not safe for work",
                    "nth" : "nice to have",
                    "nvr" : "never",
                    "nyc" : "new york city",
                    "oc" : "original content",
                    "og" : "original",
                    "ohp" : "overhead projector",
                    "oic" : "oh i see",
                    "omdb" : "over my dead body",
                    "omg" : "oh my god",
                    "omw" : "on my way",
                    "p.a" : "per annum",
                    "p.m" : "after midday",
                    "pm" : "prime minister",
                    "poc" : "people of color",
                    "pov" : "point of view",
                    "pp" : "pages",
                    "ppl" : "people",
                    "prw" : "parents are watching",
                    "ps" : "postscript",
                    "pt" : "point",
                    "ptb" : "please text back",
                    "pto" : "please turn over",
                    "qpsa" : "what happens", #"que pasa",
                    "ratchet" : "rude",
                    "rbtl" : "read between the lines",
                    "rlrt" : "real life retweet",
                    "rofl" : "rolling on the floor laughing",
                    "roflol" : "rolling on the floor laughing out loud",
                    "rotflmao" : "rolling on the floor laughing my ass off",
                    "rt" : "retweet",
                    "ruok" : "are you ok",
                    "sfw" : "safe for work",
                    "sk8" : "skate",
                    "smh" : "shake my head",
                    "sq" : "square",
                    "srsly" : "seriously",
                    "ssdd" : "same stuff different day",
                    "tbh" : "to be honest",
                    "tbs" : "tablespooful",
                    "tbsp" : "tablespooful",
                    "tfw" : "that feeling when",
                    "thks" : "thank you",
                    "tho" : "though",
                    "thx" : "thank you",
                    "tia" : "thanks in advance",
                    "til" : "today i learned",
                    "tl;dr" : "too long i did not read",
                    "tldr" : "too long i did not read",
                    "tmb" : "tweet me back",
                    "tntl" : "trying not to laugh",
                    "ttyl" : "talk to you later",
                    "u" : "you",
                    "u2" : "you too",
                    "u4e" : "yours for ever",
                    "utc" : "coordinated universal time",
                    "w/" : "with",
                    "w/o" : "without",
                    "w8" : "wait",
                    "wassup" : "what is up",
                    "wb" : "welcome back",
                    "wtf" : "what the fuck",
                    "wtg" : "way to go",
                    "wtpa" : "where the party at",
                    "wuf" : "where are you from",
                    "wuzup" : "what is up",
                    "wywh" : "wish you were here",
                    "yd" : "yard",
                    "ygtr" : "you got that right",
                    "ynk" : "you never know",
                    "zzz" : "sleeping bored and tired"
                    }

    sample_typos_slang_pattern = re.compile(r'(?<!\w)(' + '|'.join(re.escape(key) for key in sample_typos_slang.keys()) + r')(?!\w)')
    sample_acronyms_pattern = re.compile(r'(?<!\w)(' + '|'.join(re.escape(key) for key in sample_acronyms.keys()) + r')(?!\w)')
    sample_abbr_pattern = re.compile(r'(?<!\w)(' + '|'.join(re.escape(key) for key in sample_abbr.keys()) + r')(?!\w)')

    text = sample_typos_slang_pattern.sub(lambda x: sample_typos_slang[x.group()], text)
    text = sample_acronyms_pattern.sub(lambda x: sample_acronyms[x.group()], text)
    text = sample_abbr_pattern.sub(lambda x: sample_abbr[x.group()], text)

    #text = TextBlob(text).correct()

    return text

df["comment_text"] = df["comment_text"].apply(lambda x: contractions.fix(x))
df['comment_text'] = df['comment_text'].map(lambda comment : clean_text(comment))

df.head()

import nltk
nltk.download('punkt')

df['tokens'] = df['comment_text'].apply(lambda x: nltk.word_tokenize(x))
df['tokens']

df.head()

# Removing stopwords.
nltk.download("stopwords")
from nltk.corpus import stopwords

stop = set(stopwords.words('english'))
df['stop_removed'] = df['tokens'].apply(lambda x: [word for word in x if word not in stop])

df.head()

df['final_string'] = df['stop_removed'].apply(lambda x: ' '.join(x))

def temp_func(text):
    text = re.sub('\s+', ' ', text).strip()
    return text

df['final_string'] = df['final_string'].map(lambda comment : temp_func(comment))
df
df_full=df

string_arr = df['final_string'].tolist()
string_arr[0:6]

from sklearn.feature_extraction.text import TfidfVectorizer
tfidf = TfidfVectorizer(min_df=100,  max_features=10000,
            strip_accents='unicode', analyzer='word',ngram_range=(1,4),
            use_idf=1,smooth_idf=1,sublinear_tf=1,
            stop_words = 'english')
tfidf_vector = tfidf.fit_transform(df['final_string'])
print(tfidf_vector.shape)

df_req = df
df_req1 = df_req.drop(['comment_text', 'tokens', 'stop_removed', 'final_string'], axis = 1)
df_req1

df_vector = pd.DataFrame(tfidf_vector)
df_vector

result_df = pd.concat([df_vector, df_req1], axis=1, join='inner')
result_df

"""#Undersampling method 2"""

# df=result_df

# import pandas as pd
# import numpy as np


# # Split your data into training and testing sets
# train_df = df.sample(frac=0.8, random_state=42)
# test_df = df.drop(train_df.index)

# # Set the target size of the balanced dataset and the desired reduction
# target_size = 10000
# reduction = len(df) - target_size

# # Loop over each output column
# output_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']
# for col in output_cols:
#     # Identify the minority class
#     minority_class = train_df[col].value_counts().idxmin()

#     # Count the number of minority class samples
#     minority_count = (train_df[col] == minority_class).sum()

#     # Count the number of majority class samples
#     majority_count = (train_df[col] != minority_class).sum()

#     # Calculate the number of samples to be added
#     num_augmented_samples = min(majority_count - minority_count, reduction // len(output_cols))

#     # Generate augmented data
#     augmented_data = []
#     while len(augmented_data) < num_augmented_samples:
#         # Select a random majority class sample
#         majority_sample = train_df[train_df[col] != minority_class].sample(1).iloc[0]

#         # Flip the output value for the minority class
#         new_output = majority_sample[col]
#         new_output = 1 - new_output

#         # Create a new row with the same text and the flipped output value
#         new_row = majority_sample.copy()
#         new_row[col] = new_output
#         augmented_data.append(new_row)

#     # Append the augmented data to the training set
#     train_df = pd.concat([train_df, pd.DataFrame(augmented_data)], ignore_index=True)

#     # Reduce the size of the augmented data if it exceeds the reduction limit
#     if len(train_df) > target_size:
#         train_df = train_df.sample(n=target_size, random_state=42)

# # Save the balanced data to a new file
# balanced_df = train_df.append(test_df)
# balanced_df.to_csv('balanced_data.csv', index=False)
# balanced_df

# df=balanced_df

# import pandas as pd

# # # get the list of values in column 'B'
# # b_list = df[0].tolist()

# b_list = np.array(df[0])
# # print the list of values
# print(b_list)

# df_req_full_sam = balanced_df.drop([0,'non_toxic'], axis = 1)
# df_req_full_sam

"""#original data"""

######################################################################################################################################################################################################

df_req_full1 = df_full.drop(['comment_text', 'tokens', 'stop_removed', 'final_string','non_toxic'], axis = 1)
df_req_full1

from sklearn.feature_extraction.text import TfidfVectorizer
tfidf = TfidfVectorizer(min_df=100,  max_features=10000,
            strip_accents='unicode', analyzer='word',ngram_range=(1,4),
            use_idf=1,smooth_idf=1,sublinear_tf=1,
            stop_words = 'english')
tfidf_vector = tfidf.fit_transform(df_full['final_string'])
print(tfidf_vector.shape)
df_req_vector_full = tfidf_vector
df_req_vector_full

######################################################################################################################################################################################################

"""#joining of 2 codes"""

# df_req_full1=df_req_full_sam

# df_req_vector_full=b_list

"""#Train test split"""

x_train_big, x_test_big, y_train_big, y_test_big = train_test_split(df_req_vector_full, df_req_full1, test_size = 0.2)

# print(len(x_train_big))
# print(len(y_train_big))
# print(len(x_test_big))
# print(len(y_test_big))

"""#validating dataframe length"""

print(y_train_big.iloc[:,0])

print(x_train_big.shape)
print(len(y_train_big))

"""#Training models

#Random Forest
"""

# # Random Forest

# pred_model1 = []
# def model1(x_train_fnc, y_train_fnc, x_test_fnc,y_test_fnc, num):
#   y_train_fnc = y_train_fnc.astype('int')
#   y_test_fnc = y_test_fnc.astype('int')


#   # clf = RandomForestClassifier(n_estimators = 300, random_state = 5, max_depth = 100)

#   class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train_fnc), y=y_train_fnc)
#    # define the weighted random forest classifier
#   clf = RandomForestClassifier(n_estimators = 300, random_state = 5, max_depth = 100,class_weight={0: class_weights[0], 1: class_weights[1]})


#   clf.fit(x_train_fnc, y_train_fnc)
#   y_pred_fnc = clf.predict(x_test_fnc)
#   pred_model1.append(y_pred_fnc)
#   add = '/content/gdrive/MyDrive/Colab Notebooks/major_project/rf' + str(num) + '.sav'
#   pickle.dump(clf, open(add, 'wb'))
#   accu = accuracy_score(y_test_fnc, y_pred_fnc)
#   print(accu*100)
#   # Model evaluation
#   print(classification_report(y_test_fnc, y_pred_fnc))


# out_col_arr = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']
# for i in range(0, len(out_col_arr)):
#   name = out_col_arr[i]
#   model1(x_train_big, y_train_big[name], x_test_big, y_test_big[name], i + 1)

# print(pred_model1)

"""#Logistic Regression"""

# # Logistic Regression

# pred_model2 = []
# def model2(x_train_fnc, y_train_fnc, x_test_fnc,y_test_fnc,num):
#   y_train_fnc = y_train_fnc.astype('int')
#   y_test_fnc = y_test_fnc.astype('int')

#   class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train_fnc), y=y_train_fnc)
#    # define the weighted random forest classifier


#   clf = LogisticRegression(C = 1.0, max_iter = 100, penalty = 'l2',class_weight={0: class_weights[0], 1: class_weights[1]})
#   clf.fit(x_train_fnc, y_train_fnc)
#   y_pred_fnc = clf.predict(x_test_fnc)
#   pred_model2.append(y_pred_fnc)
#   add = '/content/gdrive/MyDrive/Colab Notebooks/major_project/lr' + str(num) + '.sav'
#   pickle.dump(clf, open(add, 'wb'))
#   accu = accuracy_score(y_test_fnc, y_pred_fnc)
#   print(accu*100)
#   # Model evaluation
#   print(classification_report(y_test_fnc, y_pred_fnc))

# out_col_arr = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']
# for i in range(0, len(out_col_arr)):
#   name = out_col_arr[i]
#   model2(x_train_big, y_train_big[name], x_test_big, y_test_big[name], i + 1)

# print(pred_model2)

"""#SVM"""

# # SVM

# pred_model3 = []
# def model3(x_train_fnc, y_train_fnc, x_test_fnc,y_test_fnc,num):
#   y_train_fnc = y_train_fnc.astype('int')
#   y_test_fnc = y_test_fnc.astype('int')

#   class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train_fnc), y=y_train_fnc)

#   clf = SVC(kernel = 'linear', C = 2.0, random_state = 500,class_weight={0: class_weights[0], 1: class_weights[1]})
#   clf.fit(x_train_fnc, y_train_fnc)
#   y_pred_fnc = clf.predict(x_test_fnc)
#   pred_model3.append(y_pred_fnc)
#   add = '/content/gdrive/MyDrive/Colab Notebooks/major_project/svm' + str(num) + '.sav'
#   pickle.dump(clf, open(add, 'wb'))
#   accu = accuracy_score(y_test_fnc, y_pred_fnc)
#   print(accu*100)
#   # Model evaluation
#   print(classification_report(y_test_fnc, y_pred_fnc))

# out_col_arr = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']
# for i in range(0, len(out_col_arr)):
#   name = out_col_arr[i]
#   model3(x_train_big, y_train_big[name], x_test_big, y_test_big[name], i + 1)

# print(pred_model3)

"""#KNN"""

# # KNN

# pred_model4 = []
# def model4(x_train_fnc, y_train_fnc, x_test_fnc,y_test_fnc,num):
#   y_train_fnc = y_train_fnc.astype('int')
#   y_test_fnc = y_test_fnc.astype('int')
#   clf = KNeighborsClassifier(algorithm = 'auto', leaf_size = 30, n_neighbors = 3)
#   clf.fit(x_train_fnc, y_train_fnc)
#   y_pred_fnc = clf.predict(x_test_fnc)
#   pred_model4.append(y_pred_fnc)
#   add = '/content/gdrive/MyDrive/Colab Notebooks/major_project/knn' + str(num) + '.sav'
#   pickle.dump(clf, open(add, 'wb'))
#   accu = accuracy_score(y_test_fnc, y_pred_fnc)
#   print(accu*100)
#   # Model evaluation
#   print(classification_report(y_test_fnc, y_pred_fnc))

# out_col_arr = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']
# for i in range(0, len(out_col_arr)):
#   name = out_col_arr[i]
#   model4(x_train_big, y_train_big[name], x_test_big, y_test_big[name], i + 1)

# print(pred_model4)

"""#GBM"""

# # GBM

# pred_model5 = []
# def model5(x_train_fnc, y_train_fnc, x_test_fnc,y_test_fnc,num):
#   y_train_fnc = y_train_fnc.astype('int')
#   y_test_fnc = y_test_fnc.astype('int')
#   clf = GradientBoostingClassifier(n_estimators = 100, max_depth = 100)
#   clf.fit(x_train_fnc, y_train_fnc)
#   y_pred_fnc = clf.predict(x_test_fnc)
#   pred_model5.append(y_pred_fnc)
#   add = '/content/gdrive/MyDrive/Colab Notebooks/major_project/gbm' + str(num) + '.sav'
#   pickle.dump(clf, open(add, 'wb'))
#   accu = accuracy_score(y_test_fnc, y_pred_fnc)
#   print(accu*100)
#   # Model evaluation
#   print(classification_report(y_test_fnc, y_pred_fnc))

# out_col_arr = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']
# for i in range(0, len(out_col_arr)):
#   name = out_col_arr[i]
#   model5(x_train_big, y_train_big[name], x_test_big, y_test_big[name], i + 1)

# print(pred_model5)

"""#Decision Tree Classifier"""

# clf_arr = []


# def temp(string):
#   x_train_fnc, x_test_fnc, y_train_fnc, y_test_fnc = train_test_split(tfidf_vector, df[string], test_size = 0.2)
#   y_train_fnc = y_train_fnc.astype('int')
#   y_test_fnc = y_test_fnc.astype('int')
#   class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train_fnc), y=y_train_fnc)

#   clf = DecisionTreeClassifier(max_depth = 100,class_weight={0: class_weights[0], 1: class_weights[1]})
#   clf.fit(x_train_fnc, y_train_fnc)
#   clf_arr.append(clf)
#   y_pred_fnc = clf.predict(x_test_fnc)
#   accu = accuracy_score(y_test_fnc, y_pred_fnc)
#   print(accu*100)
#   # Model evaluation
#   print(classification_report(y_test_fnc, y_pred_fnc))

# type_arr = ['toxic','severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']
# for i in type_arr:
#   temp(i)

# print(clf_arr)

"""# XGB classifier"""

# # XGB classifier
# from xgboost.sklearn import XGBClassifier

# pred_model7 = []
# def model7(x_train_fnc, y_train_fnc, x_test_fnc,y_test_fnc,num):
#   y_train_fnc = y_train_fnc.astype('int')
#   y_test_fnc = y_test_fnc.astype('int')
#   class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train_fnc), y=y_train_fnc)

#   clf = XGBClassifier(max_iter=500,class_weight={0: class_weights[0], 1: class_weights[1]})
#   clf.fit(x_train_fnc, y_train_fnc)
#   y_pred_fnc = clf.predict(x_test_fnc)
#   pred_model7.append(y_pred_fnc)
#   add = '/content/gdrive/MyDrive/Colab Notebooks/major_project/xgb' + str(num) + '.sav'
#   pickle.dump(clf, open(add, 'wb'))
#   accu = accuracy_score(y_test_fnc, y_pred_fnc)
#   print(accu*100)
#   print(classification_report(y_test_fnc, y_pred_fnc))

# out_col_arr = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']
# for i in range(0, len(out_col_arr)):
#   name = out_col_arr[i]
#   model7(x_train_big, y_train_big[name], x_test_big, y_test_big[name], i + 1)

# print(pred_model7)

"""#LGBM"""

# # LGBM

# from lightgbm import LGBMClassifier

# pred_model8 = []
# def model8(x_train_fnc, y_train_fnc, x_test_fnc,y_test_fnc,num):
#   y_train_fnc = y_train_fnc.astype('int')
#   y_test_fnc = y_test_fnc.astype('int')
#   class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train_fnc), y=y_train_fnc)
#   clf = LGBMClassifier(class_weight={0: class_weights[0], 1: class_weights[1]})
#   clf.fit(x_train_fnc, y_train_fnc)
#   y_pred_fnc = clf.predict(x_test_fnc)
#   pred_model8.append(y_pred_fnc)
#   add = '/content/gdrive/MyDrive/Colab Notebooks/major_project/lgbm' + str(num) + '.sav'
#   pickle.dump(clf, open(add, 'wb'))
#   accu = accuracy_score(y_test_fnc, y_pred_fnc)
#   print(accu*100)
#   print(classification_report(y_test_fnc, y_pred_fnc))

# out_col_arr = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']
# for i in range(0, len(out_col_arr)):
#   name = out_col_arr[i]
#   model8(x_train_big, y_train_big[name], x_test_big, y_test_big[name], i + 1)

# print(pred_model8)

"""#QDA model"""

# # QDA model

# from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA

# pred_model6 = []
# def model6(x_train_fnc, y_train_fnc, x_test_fnc,y_test_fnc,num):
#   y_train_fnc = y_train_fnc.astype('int')
#   y_test_fnc = y_test_fnc.astype('int')
#   clf = QDA()
#   x_train_fnc = x_train_fnc.toarray()
#   x_test_fnc = x_test_fnc.toarray()
#   clf.fit(x_train_fnc, y_train_fnc)
#   y_pred_fnc = clf.predict(x_test_fnc)
#   pred_model6.append(y_pred_fnc)
#   add = '/content/gdrive/MyDrive/Colab Notebooks/major_project/qda' + str(num) + '.sav'
#   pickle.dump(clf, open(add, 'wb'))
#   accu = accuracy_score(y_test_fnc, y_pred_fnc)
#   print(accu*100)
#   print(classification_report(y_test_fnc, y_pred_fnc))

# out_col_arr = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']
# for i in range(0, len(out_col_arr)):
#   name = out_col_arr[i]
#   model6(x_train_big, y_train_big[name], x_test_big, y_test_big[name], i + 1)

# print(pred_model6)

"""#Final Codes"""

from google.colab import drive
drive.mount('/content/gdrive')
df_test = pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/major_project/test.csv',header=None)
df_test

df_test.rename(columns = {0:'id', 1:'column_text'}, inplace = True)
df_test.head()

test_string_arr = df_test['column_text'].tolist()
test_string_arr[0:7]

# taking the best model for each output column

model_str = [['rf', 'lr', 'svm', 'knn' ,'xgb', 'lgbm'], ['rf', 'lr', 'svm', 'lgbm'], ['rf', 'lr', 'svm','xgb', 'lgbm'], ['lr', 'svm','xgb', 'lgbm'], ['rf', 'lr', 'svm' ,'xgb', 'lgbm'], ['rf', 'svm','xgb']]
models = []
for i in range(0, 6):
  temp_model = []
  for model_name in model_str[i]:
    add = '/content/gdrive/MyDrive/Colab Notebooks/major_project/' + model_name + str(i + 1) + '.sav'
    curr_model_out = pickle.load(open(add, 'rb'))
    temp_model.append(curr_model_out)
  models.append(temp_model)

def pred_prob(inp_str, model_arr_name):
  clean_str = clean_text(inp_str)
  test_vec = tfidf.transform([clean_str])
  tot_model = len(model_arr_name)
  cnt_1 = 0
  for curr_model in model_arr_name:
    y_pred = curr_model.predict(test_vec)
    y_pred = y_pred[0]
    if(y_pred == 1):
      cnt_1 += 1
  return round(cnt_1/tot_model, 3)

test_str = ":Fuck off, you anti-semitic cunt.  |"

out_prob_arr = []

for col in range(1, 7):
  out_prob_arr.append(pred_prob(test_str, models[col-1]))

print("The probabilities of each label:")
print(out_prob_arr)

out_label_arr = []

for i in range(0, 6):
  if(out_prob_arr[i] >= 0.5):
    out_label_arr.append(1)
  else:
    out_label_arr.append(0)

print("The class of each label:")
print(out_label_arr)

test_string_arr = test_string_arr[0:1000]
# test_string_arr = test_string_arr
len(test_string_arr)

# The probabilities for the first 50 comments of the test.csv file

pred_prob_big = []

for test_string in test_string_arr:
  out_prob_arr = []
  for col in range(1, 7):
    out_prob_arr.append(pred_prob(test_string, models[col - 1]))
  pred_prob_big.append(out_prob_arr)
  #print(out_prob_arr)

print(pred_prob_big)

pred_label_big = []

for i in range(0, len(pred_prob_big)):
  temp = []
  for prob in pred_prob_big[i]:
    if(prob >= 0.5):
      temp.append(1)
    else:
      temp.append(0)
  pred_label_big.append(temp)

print(pred_label_big)

df_debug = df_test.iloc[0:1000, :]
df_debug

pred_prob_big_np = np.array(pred_prob_big)
print(pred_prob_big_np)

pred_label_big_np = np.array(pred_label_big)
print(pred_label_big_np)

df_new_label = pd.DataFrame(pred_prob_big_np, columns = ['toxic','severe_toxic','obscene','threat', 'insult', 'identity_hate'])
df_new_label

df_new_label_bin = pd.DataFrame(pred_label_big_np, columns = ['toxic_label','severe_toxic_label','obscene_label','threat_label', 'insult_label', 'identity_hate_label'])
df_new_label_bin

result = pd.concat([df_debug, df_new_label, df_new_label_bin], axis=1, join='inner')
result

import os
folder_path = '/content/gdrive/MyDrive/Colab Notebooks/major_project/'
import pandas as pd
file_name = 'result.csv'  #balanced_df save hoga drive mai df namse
file_path = os.path.join(folder_path, file_name)
result.to_csv(file_path, index=False)

"""#Conclusion

Then we called the predict_prob function for the initial 1000 of the test.csv file to find the corresponding labels and probabilities of the test.csv comments because the test.csv file has around 1.5 lakh comments and it is taking very much time to predict all the 1.5 lakh comments,  and then we made the final dataframe to show the output which includes our id column, comment_text column and the output label probabilities and classes. And then at the end we save our dataframe to the google drive to download my result.csv file to upload that.
"""